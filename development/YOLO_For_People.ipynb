{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"YOLO_For_People.ipynb","version":"0.3.2","provenance":[{"file_id":"18LcLmZXYZN8jAV_i7tjTbg7Q6xwp3Cgt","timestamp":1560210189021}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"GEj-aVOZMA6X","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","!cp gdrive/My\\ Drive/Tesis_Resources/blured.png .\n","!cp gdrive/My\\ Drive/Tesis_Resources/blured1.png .\n","!cp gdrive/My\\ Drive/Tesis_Resources/deblured.png .\n","!cp gdrive/My\\ Drive/Tesis_Resources/deblured1.png .\n","!unzip yolo.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mgJLSE--kAd7","colab_type":"code","colab":{}},"source":["from models import *\n","from utils import *\n","\n","import os, sys, time, datetime, random\n","import torch\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from torch.autograd import Variable\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","from PIL import Image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"bbBCWfvwkAeM","colab_type":"code","colab":{}},"source":["config_path='config/yolov3.cfg'\n","weights_path='config/yolov3.weights'\n","class_path='config/coco.names'\n","img_size=416 #416\n","conf_thres=0.4\n","nms_thres=0.1\n","\n","# Load model and weights\n","model = Darknet(config_path, img_size=img_size)\n","model.load_weights(weights_path)\n","#print(model)\n","model.cuda()\n","model.eval()\n","classes = utils.load_classes(class_path)\n","Tensor = torch.cuda.FloatTensor "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZD5gCfQykAej","colab_type":"code","colab":{}},"source":["def detect_image(img):\n","    # scale and pad image\n","    ratio = min(img_size/img.size[0], img_size/img.size[1])\n","    imw = round(img.size[0] * ratio)\n","    imh = round(img.size[1] * ratio)\n","    img_transforms = transforms.Compose([ transforms.Resize((imh, imw)),\n","         transforms.Pad((max(int((imh-imw)/2),0), max(int((imw-imh)/2),0), max(int((imh-imw)/2),0), max(int((imw-imh)/2),0)),\n","                        (128,128,128)),\n","         transforms.ToTensor(),\n","         ])\n","    # convert image to Tensor\n","    image_tensor = img_transforms(img).float()\n","    image_tensor = image_tensor.unsqueeze_(0)\n","    input_img = Variable(image_tensor.type(Tensor))\n","    # run inference on the model and get detections\n","    with torch.no_grad():\n","        detections = model(input_img)\n","        detections = utils.non_max_suppression(detections, 80, conf_thres, nms_thres)\n","        print(detections[0])\n","    return detections[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VHGj0TZxkAeu","colab_type":"code","colab":{}},"source":["# load image and get detections\n","img_path = \"deblured.png\"\n","prev_time = time.time()\n","img = Image.open(img_path)\n","detections = detect_image(img)\n","inference_time = datetime.timedelta(seconds=time.time() - prev_time)\n","print ('Inference Time: %s' % (inference_time))\n","\n","# Get bounding-box colors\n","cmap = plt.get_cmap('tab20b')\n","colors = [cmap(i) for i in np.linspace(0, 1, 20)]\n","\n","img = np.array(img)\n","plt.figure()\n","fig, ax = plt.subplots(1, figsize=(12,9))\n","ax.imshow(img)\n","\n","pad_x = max(img.shape[0] - img.shape[1], 0) * (img_size / max(img.shape))\n","pad_y = max(img.shape[1] - img.shape[0], 0) * (img_size / max(img.shape))\n","unpad_h = img_size - pad_y\n","unpad_w = img_size - pad_x\n","print('n√∫mero de detecciones ' + str(len(detections)))\n","\n","if detections is not None:\n","    unique_labels = detections[:, -1].cpu().unique()\n","    print('unique_labels')\n","    print(unique_labels)\n","    n_cls_preds = len(unique_labels)\n","    print('n_cls_preds')\n","    print(n_cls_preds)\n","    bbox_colors = random.sample(colors, n_cls_preds)\n","    print('detections', detections)\n","    # browse detections and draw bounding boxes\n","    for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections:\n","        box_h = ((y2 - y1) / unpad_h) * img.shape[0]\n","        box_w = ((x2 - x1) / unpad_w) * img.shape[1]\n","        y1 = ((y1 - pad_y // 2) / unpad_h) * img.shape[0]\n","        x1 = ((x1 - pad_x // 2) / unpad_w) * img.shape[1]\n","        color = bbox_colors[int(np.where(unique_labels == int(cls_pred))[0])]\n","        bbox = patches.Rectangle((x1, y1), box_w, box_h, linewidth=2, edgecolor=color, facecolor='none')\n","        print('color')\n","        print(color)\n","        ax.add_patch(bbox)\n","        plt.text(x1, y1, s=classes[int(cls_pred)], color='white', verticalalignment='top',\n","                bbox={'color': color, 'pad': 0})\n","plt.axis('off')\n","# save image\n","plt.savefig(img_path.replace(\".jpg\", \"-det.jpg\"), bbox_inches='tight', pad_inches=0.0)\n","plt.show()"],"execution_count":0,"outputs":[]}]}